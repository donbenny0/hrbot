{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8c673621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement rank_bm25a (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for rank_bm25a\n"
     ]
    }
   ],
   "source": [
    "!pip install rank_bm25a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372d9413",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9307eb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import random\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6c7261ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv()\n",
    "\n",
    "class Config:\n",
    "    AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "    AZURE_OPENAI_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "    API_VERSION = \"2024-02-01\"\n",
    "    PERSIST_DIRECTORY = \"askhr_bot_vectorstore\"\n",
    "    COLLECTION_NAME = \"askhr_bot_vectorstore_collection\"\n",
    "    DYNAMODB_TABLE_NAME = os.getenv(\"DYNAMODB_TABLE_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0db1236",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = AzureOpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\",\n",
    "    azure_endpoint=Config.AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=Config.AZURE_OPENAI_API_KEY,\n",
    "    openai_api_version=Config.API_VERSION\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cfd29b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    api_key=Config.AZURE_OPENAI_API_KEY,\n",
    "    azure_endpoint=Config.AZURE_OPENAI_ENDPOINT,\n",
    "    api_version=Config.API_VERSION,\n",
    "    deployment_name=Config.AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "    temperature=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24696368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatWithLLM(prompt: str) -> str:\n",
    "    try:\n",
    "        response = llm.invoke(prompt)\n",
    "        if isinstance(response, AIMessage):\n",
    "            return response.content\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error in LLM invocation: {e}\")\n",
    "        return \"I'm having trouble processing that request right now.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca5a2299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sree Narayana Guru (1856â€“1928) was a prominent social reformer, spiritual leader, and philosopher from Kerala, India. He is best known for his efforts to promote social equality and uplift marginalized communities, particularly the lower castes in the Hindu social hierarchy. \\n\\nGuru emphasized the importance of education, self-respect, and spiritual awakening. He advocated for a society free from caste discrimination and worked towards the empowerment of the oppressed. His famous motto, \"One caste, one religion, one God for mankind,\" reflects his vision of unity and equality among all people.\\n\\nSree Narayana Guru founded several institutions, including schools and temples, that aimed to promote education and social reform. He also established the Sree Narayana Dharma Paripalana (SNDP) Yogam, an organization dedicated to the welfare of the backward communities in Kerala.\\n\\nHis teachings and philosophies continue to inspire many, and he is revered as a saint and a key figure in the social reform movement in India. His legacy is celebrated annually, particularly in Kerala, where various institutions and events honor his contributions to society.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatWithLLM(\"Who is Sreen narayana guru\")  # Test LLM invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ffc3488",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma(\n",
    "    collection_name=Config.COLLECTION_NAME,\n",
    "    embedding_function=embedding_model,\n",
    "    persist_directory=Config.PERSIST_DIRECTORY,\n",
    "    collection_metadata={\"hnsw:space\": \"cosine\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90b96262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_retrievers():\n",
    "    try:\n",
    "        raw = vectorstore.get(include=[\"documents\", \"metadatas\"])\n",
    "        docs = [\n",
    "            Document(page_content=content, metadata=metadata)\n",
    "            for content, metadata in zip(raw[\"documents\"], raw[\"metadatas\"])\n",
    "        ]\n",
    "\n",
    "        bm25_retriever = BM25Retriever.from_documents(docs, k=5)\n",
    "\n",
    "        vector_retriever = vectorstore.as_retriever(\n",
    "            search_type=\"mmr\",\n",
    "            search_kwargs={\"k\": 7, \"fetch_k\": 20, \"lambda_mult\": 0.6, \"score_threshold\": 0.7}\n",
    "        )\n",
    "\n",
    "        ensemble_retriever = EnsembleRetriever(\n",
    "            retrievers=[bm25_retriever, vector_retriever],\n",
    "            weights=[0.4, 0.6]\n",
    "        )\n",
    "\n",
    "        QUERY_PROMPT = PromptTemplate(\n",
    "            input_variables=[\"question\"],\n",
    "            template=\"\"\"You are an AI language model assistant. Your task is to generate five \n",
    "            different versions of the given user question to retrieve relevant documents from a \n",
    "            vector database. Provide these alternative questions separated by newlines.\n",
    "            Original question: {question}\"\"\"\n",
    "        )\n",
    "\n",
    "        return MultiQueryRetriever.from_llm(\n",
    "            retriever=ensemble_retriever,\n",
    "            llm=llm,\n",
    "            prompt=QUERY_PROMPT,\n",
    "            include_original=True\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing retrievers: {e}. Falling back to simple retriever.\")\n",
    "        return vectorstore.as_retriever(search_kwargs={\"k\": 5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9f10fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = initialize_retrievers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d5d4f0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from boto3.dynamodb.conditions import Key,Attr\n",
    "dynamodb = boto3.resource('dynamodb',region_name='ap-south-1')\n",
    "TABLE_NAME = Config.DYNAMODB_TABLE_NAME\n",
    "table = dynamodb.Table(TABLE_NAME)\n",
    "\n",
    "class ChatHistoryManager:\n",
    "    def __init__(self, user_id: str = \"default\", session_id: str = \"default_session\"):\n",
    "        self.user_id = user_id\n",
    "        self.session_id = session_id\n",
    "\n",
    "    def load_history(self) -> List[Dict[str, Any]]:\n",
    "        today = datetime.now().date()\n",
    "        start_time = datetime.combine(today, datetime.min.time()).isoformat()\n",
    "        end_time = datetime.combine(today, datetime.max.time()).isoformat()\n",
    "\n",
    "        try:\n",
    "            response = table.query(\n",
    "                KeyConditionExpression=Key('user_id').eq(self.user_id) & Key('timestamp').between(start_time, end_time),\n",
    "                FilterExpression=Attr('session_id').eq(self.session_id)\n",
    "            )\n",
    "            return response.get('Items', [])\n",
    "        except Exception as e:\n",
    "            print(\"Error loading from DynamoDB:\", e)\n",
    "            return []\n",
    "\n",
    "    def save_history(self, history: List[Dict[str, Any]]):\n",
    "        for entry in history:\n",
    "            item = {\n",
    "                'user_id': self.user_id,\n",
    "                'timestamp': entry.get(\"timestamp\", datetime.now().isoformat()),  # sort key\n",
    "                'session_id': entry.get(\"session_id\", self.session_id),\n",
    "                'user_message': entry.get(\"user_message\", \"\"),\n",
    "                'assistant_response': entry.get(\"assistant_response\", \"\"),\n",
    "                'summarized': entry.get(\"summarized\", False)\n",
    "            }\n",
    "\n",
    "            if \"summary\" in entry:\n",
    "                item[\"summary\"] = entry[\"summary\"]\n",
    "            if \"summary_of\" in entry:\n",
    "                item[\"summary_of\"] = entry[\"summary_of\"]\n",
    "\n",
    "            try:\n",
    "                table.put_item(Item=item)\n",
    "            except Exception as e:\n",
    "                print(\"Error writing to DynamoDB:\", e)\n",
    "\n",
    "    def summarize_if_needed(self, history: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "        unsummarized_blocks = [\n",
    "            entry for entry in history\n",
    "            if not entry.get(\"summarized\", False)\n",
    "            and entry.get(\"user_message\") and entry.get(\"assistant_response\")\n",
    "        ]\n",
    "\n",
    "        if len(unsummarized_blocks) < 5:\n",
    "            return history\n",
    "\n",
    "        history_text = \"\\n\".join(\n",
    "            f\"User: {entry['user_message']}\\nAssistant: {entry['assistant_response']}\"\n",
    "            for entry in unsummarized_blocks[:10]\n",
    "        )\n",
    "\n",
    "        summary_prompt = f\"\"\"\n",
    "        Summarize the following 10 interactions into one concise but informative summary:\n",
    "        {history_text}\n",
    "        \"\"\"\n",
    "\n",
    "        summary = llm.invoke(summary_prompt.strip())\n",
    "        if isinstance(summary, AIMessage):\n",
    "            summary = summary.content\n",
    "\n",
    "        summary_entry = {\n",
    "            \"role\": \"system\",\n",
    "            \"summary\": summary,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"session_id\": self.session_id,\n",
    "            \"summarized\": True,\n",
    "            \"summary_of\": [entry[\"timestamp\"] for entry in unsummarized_blocks[:10]]\n",
    "        }\n",
    "\n",
    "        history = [entry for entry in history if entry not in unsummarized_blocks[:10]]\n",
    "        history.insert(0, summary_entry)\n",
    "        return history\n",
    "\n",
    "    def append_chat_pair(self, history: List[Dict[str, Any]], user_msg: str, assistant_msg: str) -> List[Dict[str, Any]]:\n",
    "        new_entry = {\n",
    "            \"user_message\": user_msg,\n",
    "            \"assistant_response\": assistant_msg,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"session_id\": self.session_id,\n",
    "            \"summarized\": False\n",
    "        }\n",
    "\n",
    "        history.append(new_entry)\n",
    "        self.save_history([new_entry])  # Save only the new one\n",
    "        return self.summarize_if_needed(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58e20417",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseEvaluator:\n",
    "    def __init__(self):\n",
    "        self.evaluation_history = []\n",
    "    \n",
    "    def log_interaction(self, user_input, response, context, retrieval_time):\n",
    "        self.evaluation_history.append({\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"input\": user_input,\n",
    "            \"response\": response,\n",
    "            \"context_relevance\": self._calculate_context_relevance(response, context),\n",
    "            \"retrieval_time\": retrieval_time\n",
    "        })\n",
    "        self.evaluation_history = self.evaluation_history[-100:]\n",
    "        \n",
    "    def _calculate_context_relevance(self, response, context):\n",
    "        if not context:\n",
    "            return 0\n",
    "        context_keywords = set(\" \".join(context).split())\n",
    "        response_keywords = set(response.split())\n",
    "        common = context_keywords & response_keywords\n",
    "        return len(common) / len(context_keywords) if context_keywords else 0\n",
    "    \n",
    "    def get_metrics(self):\n",
    "        if not self.evaluation_history:\n",
    "            return {}\n",
    "        avg_relevance = sum(\n",
    "            e[\"context_relevance\"] for e in self.evaluation_history\n",
    "        ) / len(self.evaluation_history)\n",
    "        avg_time = sum(\n",
    "            e[\"retrieval_time\"] for e in self.evaluation_history\n",
    "        ) / len(self.evaluation_history)\n",
    "        return {\n",
    "            \"avg_context_relevance\": avg_relevance,\n",
    "            \"avg_response_time\": avg_time,\n",
    "            \"total_interactions\": len(self.evaluation_history)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "366f5621",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = ResponseEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e92262df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dynamic_prompt(user_input: str, history: List) -> PromptTemplate:\n",
    "    sensitive_keywords = [\"complaint\", \"harassment\", \"grievance\", \"termination\"]\n",
    "    policy_keywords = [\"policy\", \"rule\", \"guideline\"]\n",
    "    benefit_keywords = [\"benefit\", \"pto\", \"leave\", \"insurance\"]\n",
    "    \n",
    "    if any(kw in user_input.lower() for kw in sensitive_keywords):\n",
    "        instructions = \"This is a sensitive topic. Be professional and direct the user to official HR channels if appropriate.\"\n",
    "    elif any(kw in user_input.lower() for kw in policy_keywords):\n",
    "        instructions = \"Provide exact policy details with reference to the policy document when possible.\"\n",
    "    elif any(kw in user_input.lower() for kw in benefit_keywords):\n",
    "        instructions = \"Include eligibility requirements and any limitations for benefits mentioned.\"\n",
    "    else:\n",
    "        instructions = \"Respond helpfully and professionally.\"\n",
    "    \n",
    "    template = f\"\"\"You are an HR assistant for a company. Use the following context to answer the question at the end.\n",
    "If you don't know the answer, say you don't know. Be concise but helpful.\n",
    "\n",
    "Context:\n",
    "{{context}}\n",
    "\n",
    "Conversation history:\n",
    "{{chat_history}}\n",
    "\n",
    "Question: {{input}}\n",
    "\n",
    "Considerations:\n",
    "1. {instructions}\n",
    "2. Format lists and important details clearly\n",
    "3. Provide sources when available\n",
    "\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    return PromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8615ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def docs_to_serializable(docs: List[Document]) -> List[Dict[str, Any]]:\n",
    "    return [\n",
    "        {\n",
    "            \"content\": doc.page_content,\n",
    "            \"metadata\": doc.metadata\n",
    "        }\n",
    "        for doc in docs\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cab651c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(user_input: str, user_id: str = \"default\", session_id: str = \"default_session\") -> str:\n",
    "    history_manager = ChatHistoryManager(user_id, session_id)\n",
    "    chat_history = history_manager.load_history()\n",
    "\n",
    "    formatted_history = []\n",
    "    for entry in chat_history:\n",
    "        if entry.get(\"summarized\", False):\n",
    "            formatted_history.append((\"system\", entry[\"summary\"]))\n",
    "        else:\n",
    "            formatted_history.append((\"user\", entry[\"user_message\"]))\n",
    "            formatted_history.append((\"assistant\", entry[\"assistant_response\"]))\n",
    "\n",
    "\n",
    "\n",
    "    contextualize_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Given a chat history and the latest user question, formulate a standalone question.\"),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ])\n",
    "\n",
    "    history_aware_retriever = create_history_aware_retriever(llm, retriever, contextualize_prompt)\n",
    "    qa_prompt = get_dynamic_prompt(user_input, chat_history)\n",
    "    question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "    rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "\n",
    "    start_time = time()\n",
    "    try:\n",
    "        response = rag_chain.invoke({\n",
    "            \"input\": user_input,\n",
    "            \"chat_history\": formatted_history\n",
    "        })\n",
    "        elapsed = time() - start_time\n",
    "\n",
    "        # Make sure response[\"answer\"] is a plain string\n",
    "        answer = response[\"answer\"]\n",
    "        if isinstance(answer, AIMessage):\n",
    "            answer = answer.content\n",
    "\n",
    "\n",
    "        chat_history = history_manager.append_chat_pair(\n",
    "            chat_history, user_msg=user_input, assistant_msg=answer\n",
    "        )\n",
    "\n",
    "        history_manager.save_history(chat_history)\n",
    "\n",
    "        return answer\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in RAG chain: {e}\")\n",
    "        fallback_responses = [\n",
    "            f\"I'm having trouble accessing that information. Could you rephrase your question? (Error: {str(e)[:50]})\",\n",
    "            \"My knowledge base seems to be unavailable at the moment. Please try again later.\",\n",
    "            \"I encountered an unexpected error while processing your request.\"\n",
    "        ]\n",
    "        return random.choice(fallback_responses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4313e91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The CEO of AyataCommerce is Shine Mathew. Here are some key details about him:\\n\\n- **Role**: Founder and CEO of AyataCommerce.\\n- **Vision**: He emphasizes the importance of a transparent, open, and respectful work culture at AyataCommerce.\\n- **Leadership Style**: Shine promotes mutual trust and encourages employees to connect, communicate, and collaborate effectively.\\n- **Company Philosophy**: He advocates for a work environment that balances professional commitments with personal well-being.\\n\\nFor more information about AyataCommerce and its values, please refer to the company's official communications or internal resources.\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"what do you know about the CEO of AyataCommerce?\",\"123\",\"1234\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c50d19b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Shine Mathew is the CEO and Founder of AyataCommerce. Here are some key details about him:\\n\\n- **Role**: Founder and CEO of AyataCommerce.\\n- **Vision**: He emphasizes the importance of a transparent, open, and respectful work culture.\\n- **Leadership Style**: Promotes mutual trust and encourages effective communication and collaboration among employees.\\n- **Company Philosophy**: Advocates for a balance between professional commitments and personal well-being, fostering a supportive environment for employees.\\n\\nFor further insights, you may refer to internal communications or company resources related to AyataCommerce.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"what do you know about him?\",\"123\",\"1234\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7520333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The core values of AyataCommerce are:\\n\\n1. **Empathy**: Emphasizing understanding and valuing diverse perspectives within the global team.\\n2. **Trust**: Building a transparent and respectful environment that fosters mutual trust.\\n3. **Adaptability**: Encouraging flexibility and openness to innovative ideas and changes.\\n\\nThese values guide the company's working practices and interactions with clients and each other.\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"What are the core values of the company?\",\"123\",\"1234\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12991199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in RAG chain: Object of type AIMessage is not JSON serializable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'My knowledge base seems to be unavailable at the moment. Please try again later.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"Which among the values reflects about the flexibility?\",\"123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7088a6f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, you can take a half-day leave if you are suddenly sick. Here are the key points to consider:\\n\\n### Eligibility Requirements:\\n1. **Notification**: You must inform your manager as soon as possible on the first day of your absence.\\n2. **Duration of Absence**: If you are going to be away from work for more than 48 hours, you must notify your manager and may need to provide a medical certificate if the absence extends beyond two days.\\n\\n### Limitations:\\n- **Sick Pay**: Ensure you understand the rules regarding company sick pay. If you have any uncertainties, it's advisable to ask payroll for clarification.\\n- **Documentation**: If your illness continues beyond the term of your medical certificate, further documentation may be required to confirm your sickness.\\n\\n### Additional Notes:\\n- You should record your leave accurately in Zoho.\\n- If you are sick during a holiday, you must notify your manager promptly to potentially treat it as sick leave rather than annual leave.\\n\\nFor more detailed information, you can refer to the company's Leave Guidelines or consult with HR.\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"Is it ok to take a half day leave if i am sick suddenly?\",\"123\",\"1234\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
