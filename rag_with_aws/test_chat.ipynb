{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03a12be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import random\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_aws import ChatBedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d36097b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "class Config:\n",
    "    AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "    AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "    KB_ID = os.getenv(\"KB_ID\")\n",
    "    MODEL_ARN = os.getenv(\"MODEL_ARN\")\n",
    "    DYNAMODB_TABLE_NAME = os.getenv(\"DYNAMODB_TABLE_NAME\")\n",
    "    AWS_REGION = os.getenv(\"AWS_REGION\", \"us-east-1\")\n",
    "\n",
    "# Initialize AWS Bedrock Runtime Client\n",
    "client = boto3.client(\"bedrock-agent-runtime\", region_name=Config.AWS_REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af121a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatBedrock(\n",
    "    model=\"amazon.nova-pro-v1:0\",\n",
    "    region_name=Config.AWS_REGION,\n",
    "    beta_use_converse_api=True,\n",
    "    streaming=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88a4ba1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from boto3.dynamodb.conditions import Key,Attr\n",
    "dynamodb = boto3.resource('dynamodb',region_name=Config.AWS_REGION)\n",
    "TABLE_NAME = Config.DYNAMODB_TABLE_NAME\n",
    "table = dynamodb.Table(TABLE_NAME)\n",
    "\n",
    "class ChatHistoryManager:\n",
    "    def __init__(self, user_id: str = \"default\", session_id: str = \"default_session\"):\n",
    "        self.user_id = user_id\n",
    "        self.session_id = session_id\n",
    "\n",
    "    def load_history(self) -> List[Dict[str, Any]]:\n",
    "        today = datetime.now().date()\n",
    "        start_time = datetime.combine(today, datetime.min.time()).isoformat()\n",
    "        end_time = datetime.combine(today, datetime.max.time()).isoformat()\n",
    "\n",
    "        try:\n",
    "            response = table.query(\n",
    "                KeyConditionExpression=Key('user_id').eq(self.user_id) & Key('timestamp').between(start_time, end_time),\n",
    "                FilterExpression=Attr('session_id').eq(self.session_id)\n",
    "            )\n",
    "            return response.get('Items', [])\n",
    "        except Exception as e:\n",
    "            print(\"Error loading from DynamoDB:\", e)\n",
    "            return []\n",
    "\n",
    "    def save_history(self, history: List[Dict[str, Any]]):\n",
    "        for entry in history:\n",
    "            item = {\n",
    "                'user_id': self.user_id,\n",
    "                'timestamp': entry.get(\"timestamp\", datetime.now().isoformat()),\n",
    "                'session_id': entry.get(\"session_id\", self.session_id),\n",
    "                'user_message': entry.get(\"user_message\", \"\"),\n",
    "                'assistant_response': entry.get(\"assistant_response\", \"\"),\n",
    "                'summarized': entry.get(\"summarized\", False)\n",
    "            }\n",
    "\n",
    "            if \"summary\" in entry:\n",
    "                item[\"summary\"] = entry[\"summary\"]\n",
    "            if \"summary_of\" in entry:\n",
    "                item[\"summary_of\"] = entry[\"summary_of\"]\n",
    "\n",
    "            try:\n",
    "                table.put_item(Item=item)\n",
    "            except Exception as e:\n",
    "                print(\"Error writing to DynamoDB:\", e)\n",
    "\n",
    "    def summarize_if_needed(self, history: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "        unsummarized_blocks = [\n",
    "            entry for entry in history\n",
    "            if not entry.get(\"summarized\", False)\n",
    "            and entry.get(\"user_message\") and entry.get(\"assistant_response\")\n",
    "        ]\n",
    "\n",
    "        if len(unsummarized_blocks) < 5:\n",
    "            return history\n",
    "\n",
    "        history_text = \"\\n\".join(\n",
    "            f\"User: {entry['user_message']}\\nAssistant: {entry['assistant_response']}\"\n",
    "            for entry in unsummarized_blocks[:10]\n",
    "        )\n",
    "\n",
    "        summary_prompt = f\"\"\"\n",
    "        Summarize the following 10 interactions into one concise but informative summary:\n",
    "        {history_text}\n",
    "        \"\"\"\n",
    "\n",
    "        summary = llm.invoke(summary_prompt.strip())\n",
    "        if isinstance(summary, AIMessage):\n",
    "            summary = summary.content\n",
    "\n",
    "        summary_entry = {\n",
    "            \"role\": \"system\",\n",
    "            \"summary\": summary,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"session_id\": self.session_id,\n",
    "            \"summarized\": True,\n",
    "            \"summary_of\": [entry[\"timestamp\"] for entry in unsummarized_blocks[:10]]\n",
    "        }\n",
    "\n",
    "        history = [entry for entry in history if entry not in unsummarized_blocks[:10]]\n",
    "        history.insert(0, summary_entry)\n",
    "        return history\n",
    "\n",
    "    def append_chat_pair(self, history: List[Dict[str, Any]], user_msg: str, assistant_msg: str) -> List[Dict[str, Any]]:\n",
    "        new_entry = {\n",
    "            \"user_message\": user_msg,\n",
    "            \"assistant_response\": assistant_msg,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"session_id\": self.session_id,\n",
    "            \"summarized\": False\n",
    "        }\n",
    "\n",
    "        history.append(new_entry)\n",
    "        self.save_history([new_entry])\n",
    "        return self.summarize_if_needed(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "419b727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_from_kb(input_text: str):\n",
    "    if not isinstance(input_text, str):\n",
    "        raise TypeError(\"Expected input_text to be a string\")\n",
    "\n",
    "    try:\n",
    "        response = client.retrieve_and_generate(\n",
    "            input={'text': input_text},\n",
    "            retrieveAndGenerateConfiguration={\n",
    "    \"type\": \"KNOWLEDGE_BASE\",\n",
    "    \"knowledgeBaseConfiguration\": {\n",
    "        \"knowledgeBaseId\": Config.KB_ID,\n",
    "        \"modelArn\":Config.MODEL_ARN,\n",
    "        \"retrievalConfiguration\": {\n",
    "            \"vectorSearchConfiguration\": {\n",
    "                \"numberOfResults\": 5\n",
    "            }\n",
    "        },\n",
    "        \"generationConfiguration\": {\n",
    "            \"promptTemplate\": {\n",
    "                \"textPromptTemplate\": \"You are a precise HR assistant at Ayatacommerce that answers questions using ONLY the provided context and consider you as an employee of ayatacommerce responsible for responding to all queries related to the company by other employees.\\r\\n\\r\\nContext:\\r\\n$search_results$\\r\\n\\r\\nQuestion: $query$\\r\\n\\r\\nAlways respond in a concise and professional manner and also just don't answer simply if always create a scentence with the answer.\\r\\nNOTE:Do not mention the source of the context or the document name in your answer or anything related to the provided context.\\r\\nIf no information is avialable in the context, please respond with the following data:\\r\\nContact HR at Ayatacommerce for assistance: hr@ayatacommerce.com \\r\\nHuman Resourse email: hr@ayatacommerce.com\\r\\n\\r\\nRules:\\r\\n1. If the context contains relevant information, provide a concise answer based solely on that.\\r\\n2. If the question asks about something NOT in the context, respond ONLY with: 'I don't have this information in my knowledge base. Please contact hr@ayatacommerce.com for assistance.'\\r\\n3. Never infer or make up information not explicitly stated in the context.\\r\\n4. If the question is ambiguous or unclear, ask for clarification.\\r\\n5. Do not provide any personal opinions or subjective statements.\\r\\n6. Always maintain a professional tone and language.\\r\\n7. Avoid using filler phrases like 'I think' or 'In my opinion'.\\r\\n8. If the context is too long, summarize it before answering.\\r\\n10. If the question is a yes/no question, provide a clear yes or no answer based on the context.\\r\\n11. If the question is a list, provide a clear and concise list based on the context.\\r\\n12. If the question is a how-to question, provide a clear and concise step-by-step guide based on the context.\\r\\n13. If the question is a why question, provide a clear and concise explanation based on the context.\\r\\n14. If the question is a when question, provide a clear and concise answer based on the context.\\r\\n\\r\\nAnswer:\\\"\\\"\\\"\"\n",
    "            },\n",
    "            \"inferenceConfig\": {\n",
    "                \"textInferenceConfig\": {\n",
    "                    \"temperature\": 0,\n",
    "                    \"topP\": 0.9,\n",
    "                    \"maxTokens\": 512,\n",
    "                    \"stopSequences\": []\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"orchestrationConfiguration\": {\n",
    "            \"inferenceConfig\": {\n",
    "                \"textInferenceConfig\": {\n",
    "                    \"temperature\": 0,\n",
    "                    \"topP\": 0.9,\n",
    "                    \"maxTokens\": 512,\n",
    "                    \"stopSequences\": []\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving knowledge base: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32738e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_question(user_input: str, chat_history: List) -> str:\n",
    "    messages = []\n",
    "    \n",
    "    # Ensure we start with a user message\n",
    "    if not chat_history or isinstance(chat_history[0], HumanMessage):\n",
    "        messages.append(HumanMessage(content=\"You are a helpful assistant that rewrites questions to be standalone.\"))\n",
    "    \n",
    "    # Add conversation history (alternating user/assistant messages)\n",
    "    for entry in chat_history[-10:]:  # Keep only the latest 10 for context\n",
    "        messages.append(entry)\n",
    "    \n",
    "    retriever_prompt = (\n",
    "        \"Given a chat history and the latest user question which might reference context in the chat history, \"\n",
    "        \"formulate a standalone question which can be understood without the chat history. \"\n",
    "        \"Do NOT answer the question, just reformulate it if needed and otherwise return it as is. \"\n",
    "        \"Latest question: {question}\"\n",
    "    )\n",
    "    \n",
    "    messages.append(HumanMessage(content=retriever_prompt.format(question=user_input)))\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke(messages)\n",
    "        return response.content if isinstance(response, AIMessage) else str(response)\n",
    "    except Exception as e:\n",
    "        print(f\"Error rewriting question: {e}\")\n",
    "        return user_input  # Fallback to original input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "035d23a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(user_input: str, user_id: str = \"default\", session_id: str = \"default_session\") -> str:\n",
    "    history_manager = ChatHistoryManager(user_id, session_id)\n",
    "    chat_history = history_manager.load_history()\n",
    "\n",
    "    try:\n",
    "        # Format history for context\n",
    "        formatted_history = []\n",
    "        for entry in chat_history:\n",
    "            if entry.get(\"summarized\", False):\n",
    "                formatted_history.append(AIMessage(content=entry[\"summary\"]))\n",
    "            else:\n",
    "                formatted_history.append(HumanMessage(content=entry[\"user_message\"]))\n",
    "                formatted_history.append(AIMessage(content=entry[\"assistant_response\"]))\n",
    "\n",
    "        # Rewrite the question to be standalone\n",
    "        standalone_question = rewrite_question(user_input, formatted_history)\n",
    "        print(f\"Standalone question: {standalone_question[0]['text']}\")\n",
    "\n",
    "        # Call retrieve_and_generate with clean string\n",
    "        response = retrieve_from_kb(standalone_question[0]['text'])\n",
    "        if not response:\n",
    "            raise ValueError(\"No response returned from retrieve_from_kb\")\n",
    "\n",
    "        # Handle response format\n",
    "        if isinstance(response, dict) and 'output' in response:\n",
    "            answer = response['output'].get('text', 'Sorry, I could not find information about that topic.')\n",
    "        else:\n",
    "            answer = 'Sorry, I could not find information about that topic.'\n",
    "\n",
    "        # Save chat\n",
    "        chat_history = history_manager.append_chat_pair(\n",
    "            chat_history, user_msg=user_input, assistant_msg=answer\n",
    "        )\n",
    "        history_manager.save_history(chat_history)\n",
    "\n",
    "        return answer\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in RAG chain: {e}\")\n",
    "        fallback_responses = [\n",
    "            \"I'm having trouble accessing that information. Could you rephrase your question?\",\n",
    "            \"My knowledge base seems to be unavailable at the moment. Please try again later.\",\n",
    "            \"I encountered an unexpected error while processing your request.\"\n",
    "        ]\n",
    "        return random.choice(fallback_responses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f337b7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standalone question: What is known about the CEO of AyataCommerce?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The CEO of AyataCommerce is Shine Mathew, who is also the founder of the company.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"what do you know about the CEO of AyataCommerce?\",\"123\",\"1234\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3647385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standalone question: Could you provide information about AyataCommerce, including its services, history, and key personnel?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"AyataCommerce is dedicated to providing structure for clients and a framework to understand core issues, focusing on building, measuring, and learning. The company supports customers in realizing their aspirations, understanding their points of contention, and providing structure and flexibility for deeper issue understanding. AyataCommerce allows customers to determine success and pivot when necessary, ensuring promises are delivered and both customers and employees are successful.\\n\\nThe journey of AyataCommerce includes significant milestones such as the establishment of a partnership with SAP in 2017, the founding of Ayatacommerce in Bracknell in 2016, the implementation of a 'Remote First' culture, the start of India Operations, and the opening of a Regional Office in Bangalore. In 2020, a new website was launched, and in 2021, an office was opened in Kochi.\\n\\nAyataCommerce's values include EMPATHY, which fosters a worldwide team with diverse mindsets, personalities, and viewpoints, promoting an empathy-driven culture for better understanding, cohesive work, and remarkable results.\\n\\nKey personnel include Shine Mathew, CEO and Founder, who welcomes everyone to AyataCommerce and emphasizes what it means to work there. Other notable employees are Robin Roy, Senior Quality Engineer; Cindy Lee, Technical Lead; Sonia Antony, Senior Technical Writer; and Namrita Gupta, Project Manager, all of whom highlight the company's supportive and inclusive culture.\\n\\nFor more detailed information, please contact HR at Ayatacommerce: hr@ayatacommerce.com.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"Tell me about this company\",\"123\",\"1234\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336e6ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chat(\"what do you know about the CEO of AyataCommerce?\", \"123\", \"1234\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688fdf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chat(\"what do you know about him\", \"123\", \"1234\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4c46978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standalone question: What is the current net worth of the specified company?\n",
      "I don't have this information in my knowledge base. Please contact hr@ayatacommerce.com for assistance.\n"
     ]
    }
   ],
   "source": [
    "print(chat(\"What is the net worth of this company?\", \"123\", \"1234\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cb922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chat(\"what do you know about him\", \"123\", \"123\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
