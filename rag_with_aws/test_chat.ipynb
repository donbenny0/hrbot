{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03a12be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import random\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_aws import ChatBedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d36097b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "class Config:\n",
    "    AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "    AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "    KB_ID = os.getenv(\"KB_ID\")\n",
    "    MODEL_ARN = os.getenv(\"MODEL_ARN\")\n",
    "    DYNAMODB_TABLE_NAME = os.getenv(\"DYNAMODB_TABLE_NAME\")\n",
    "    AWS_REGION = os.getenv(\"AWS_REGION\", \"us-east-1\")\n",
    "\n",
    "# Initialize AWS Bedrock Runtime Client\n",
    "client = boto3.client(\"bedrock-agent-runtime\", region_name=Config.AWS_REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af121a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatBedrock(\n",
    "    model=\"amazon.nova-pro-v1:0\",\n",
    "    region_name=Config.AWS_REGION,\n",
    "    beta_use_converse_api=True,\n",
    "    streaming=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68c8fd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from boto3.dynamodb.conditions import Key,Attr\n",
    "dynamodb = boto3.resource('dynamodb',region_name=Config.AWS_REGION)\n",
    "TABLE_NAME = Config.DYNAMODB_TABLE_NAME\n",
    "table = dynamodb.Table(TABLE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a4ba1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "419b727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_from_kb(input_text: str):\n",
    "    if not isinstance(input_text, str):\n",
    "        raise TypeError(\"Expected input_text to be a string\")\n",
    "\n",
    "    try:\n",
    "        response = client.retrieve_and_generate(\n",
    "            input={'text': input_text},\n",
    "            retrieveAndGenerateConfiguration={\n",
    "    \"type\": \"KNOWLEDGE_BASE\",\n",
    "    \"knowledgeBaseConfiguration\": {\n",
    "        \"knowledgeBaseId\": Config.KB_ID,\n",
    "        \"modelArn\":Config.MODEL_ARN,\n",
    "        \"retrievalConfiguration\": {\n",
    "            \"vectorSearchConfiguration\": {\n",
    "                \"numberOfResults\": 5\n",
    "            }\n",
    "        },\n",
    "        \"generationConfiguration\": {\n",
    "            \"promptTemplate\": {\n",
    "                \"textPromptTemplate\": \"You are a precise HR assistant at Ayatacommerce that answers questions using ONLY the provided context and consider you as an employee of ayatacommerce responsible for responding to all queries related to the company by other employees.\\r\\n\\r\\nContext:\\r\\n$search_results$\\r\\n\\r\\nQuestion: $query$\\r\\n\\r\\nAlways respond in a concise and professional manner and also just don't answer simply if always create a scentence with the answer.\\r\\nNOTE:Do not mention the source of the context or the document name in your answer or anything related to the provided context.\\r\\nIf no information is avialable in the context, please respond with the following data:\\r\\nContact HR at Ayatacommerce for assistance: hr@ayatacommerce.com \\r\\nHuman Resourse email: hr@ayatacommerce.com\\r\\n\\r\\nRules:\\r\\n1. If the context contains relevant information, provide a concise answer based solely on that.\\r\\n2. If the question asks about something NOT in the context, respond ONLY with: 'I don't have this information in my knowledge base. Please contact hr@ayatacommerce.com for assistance.'\\r\\n3. Never infer or make up information not explicitly stated in the context.\\r\\n4. If the question is ambiguous or unclear, ask for clarification.\\r\\n5. Do not provide any personal opinions or subjective statements.\\r\\n6. Always maintain a professional tone and language.\\r\\n7. Avoid using filler phrases like 'I think' or 'In my opinion'.\\r\\n8. If the context is too long, summarize it before answering.\\r\\n10. If the question is a yes/no question, provide a clear yes or no answer based on the context.\\r\\n11. If the question is a list, provide a clear and concise list based on the context.\\r\\n12. If the question is a how-to question, provide a clear and concise step-by-step guide based on the context.\\r\\n13. If the question is a why question, provide a clear and concise explanation based on the context.\\r\\n14. If the question is a when question, provide a clear and concise answer based on the context.\\r\\n\\r\\nAnswer:\\\"\\\"\\\"\"\n",
    "            },\n",
    "            \"inferenceConfig\": {\n",
    "                \"textInferenceConfig\": {\n",
    "                    \"temperature\": 0,\n",
    "                    \"topP\": 0.9,\n",
    "                    \"maxTokens\": 512,\n",
    "                    \"stopSequences\": []\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"orchestrationConfiguration\": {\n",
    "            \"inferenceConfig\": {\n",
    "                \"textInferenceConfig\": {\n",
    "                    \"temperature\": 0,\n",
    "                    \"topP\": 0.9,\n",
    "                    \"maxTokens\": 512,\n",
    "                    \"stopSequences\": []\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving knowledge base: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32738e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_question(user_input: str, chat_history: List) -> str:\n",
    "    messages = []\n",
    "    \n",
    "    # Ensure we start with a user message\n",
    "    if not chat_history or isinstance(chat_history[0], HumanMessage):\n",
    "        messages.append(HumanMessage(content=\"You are a helpful assistant that rewrites questions to be standalone.\"))\n",
    "    \n",
    "    # Add conversation history (alternating user/assistant messages)\n",
    "    for entry in chat_history[-10:]:  # Keep only the latest 10 for context\n",
    "        messages.append(entry)\n",
    "    \n",
    "    retriever_prompt = (\n",
    "        \"Given a chat history and the latest user question which might reference context in the chat history, \"\n",
    "        \"formulate a standalone question which can be understood without the chat history. \"\n",
    "        \"Do NOT answer the question, just reformulate it if needed and otherwise return it as is. \"\n",
    "        \"Latest question: {question}\"\n",
    "    )\n",
    "    \n",
    "    messages.append(HumanMessage(content=retriever_prompt.format(question=user_input)))\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke(messages)\n",
    "        return response.content if isinstance(response, AIMessage) else str(response)\n",
    "    except Exception as e:\n",
    "        print(f\"Error rewriting question: {e}\")\n",
    "        return user_input  # Fallback to original input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1bbc3e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatHistoryManager:\n",
    "    def __init__(self, user_id: str = \"default\", session_id: str = \"default_session\"):\n",
    "        self.user_id = user_id\n",
    "        self.session_id = session_id\n",
    "\n",
    "    def load_history(self) -> Dict[str, Any]:\n",
    "        try:\n",
    "            response = table.get_item(\n",
    "                Key={\n",
    "                    'user_id': self.user_id,\n",
    "                    'session_id': self.session_id\n",
    "                }\n",
    "            )\n",
    "            return response.get('Item', {\n",
    "                'user_id': self.user_id,\n",
    "                'session_id': self.session_id,\n",
    "                'messages': []\n",
    "            }) \n",
    "        except Exception as e:\n",
    "            print(\"Error loading from DynamoDB:\", e)\n",
    "            return {\n",
    "                'user_id': self.user_id,\n",
    "                'session_id': self.session_id,\n",
    "                'messages': []\n",
    "            }\n",
    "            \n",
    "    def save_history(self, history: Dict[str, Any]):\n",
    "        try:\n",
    "            table.put_item(Item=history)\n",
    "        except Exception as e:\n",
    "            print(\"Error writing to DynamoDB:\", e)\n",
    "\n",
    "    def summarize_if_needed(self, history: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        messages = history['messages']\n",
    "        if len(messages) < 5:\n",
    "            return history\n",
    "\n",
    "        # Get the last 10 unsummarized messages\n",
    "        unsummarized_messages = messages[-10:]\n",
    "        \n",
    "        history_text = \"\\n\".join(\n",
    "            f\"User: {msg['user']['content']}\\nAssistant: {msg['assistant']['content']}\"\n",
    "            for msg in unsummarized_messages\n",
    "        )\n",
    "\n",
    "        summary_prompt = f\"\"\"\n",
    "        Summarize the following 10 interactions into one concise but informative summary:\n",
    "        {history_text}\n",
    "        \"\"\"\n",
    "\n",
    "        summary = llm.invoke(summary_prompt.strip())\n",
    "        if isinstance(summary, AIMessage):\n",
    "            summary = summary.content\n",
    "\n",
    "        # Create a summary message\n",
    "        summary_message = {\n",
    "            \"user\": {\n",
    "                \"content\": summary,\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"is_summary\": True\n",
    "            },\n",
    "            \"assistant\": {\n",
    "                \"content\": \"This is a summary of previous interactions\",\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"is_summary\": True\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Keep only messages that weren't summarized\n",
    "        history['messages'] = messages[:-10] + [summary_message]\n",
    "        return history\n",
    "\n",
    "    def append_chat_pair(self, history: Dict[str, Any], user_msg: str, assistant_msg: str) -> Dict[str, Any]:\n",
    "        new_entry = {\n",
    "            \"user\": {\n",
    "                \"content\": user_msg,\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            },\n",
    "            \"assistant\": {\n",
    "                \"content\": assistant_msg,\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "        }\n",
    "\n",
    "        history['messages'].append(new_entry)\n",
    "        self.save_history(history)\n",
    "        return self.summarize_if_needed(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545ddbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_history_within_token_limit(user_id, session_id) -> bool:\n",
    "    try:\n",
    "        history_data = ChatHistoryManager(user_id, session_id).load_history()\n",
    "\n",
    "        messages = (\n",
    "            message.get('user', {}).get('content', '') + ' ' +\n",
    "            message.get('assistant', {}).get('content', '')\n",
    "            for message in history_data.get('messages', [])\n",
    "        )\n",
    "        combined_text = ' '.join(messages)\n",
    "        total_tokens = llm.get_num_tokens(combined_text)\n",
    "        return total_tokens < 280000\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[Token Count Error] User: {user_id}, Session: {session_id}, Error: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "035d23a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(user_input: str, user_id: str = \"default\", session_id: str = \"default_session\") -> str:\n",
    "    history_manager = ChatHistoryManager(user_id, session_id)\n",
    "    chat_history = history_manager.load_history()\n",
    "\n",
    "    try:\n",
    "        # Format history for context\n",
    "        formatted_history = []\n",
    "        for entry in chat_history['messages']:\n",
    "            user_content = entry['user']['content']\n",
    "            assistant_content = entry['assistant']['content']\n",
    "            \n",
    "            if entry['user'].get('is_summary', False):\n",
    "                formatted_history.append(AIMessage(content=user_content))\n",
    "            else:\n",
    "                formatted_history.append(HumanMessage(content=user_content))\n",
    "                formatted_history.append(AIMessage(content=assistant_content))\n",
    "\n",
    "        # Rewrite the question to be standalone\n",
    "        # print(formatted_history)\n",
    "        standalone_question = rewrite_question(user_input, formatted_history)\n",
    "        print(f\"Standalone question: {standalone_question[0]['text']}\")\n",
    "\n",
    "        # Call retrieve_and_generate with clean string\n",
    "        response = retrieve_from_kb(standalone_question[0]['text'])\n",
    "        if not response:\n",
    "            raise ValueError(\"No response returned from retrieve_from_kb\")\n",
    "\n",
    "        # Handle response format\n",
    "        if isinstance(response, dict) and 'output' in response:\n",
    "            answer = response['output'].get('text', 'Sorry, I could not find information about that topic.')\n",
    "        else:\n",
    "            answer = 'Sorry, I could not find information about that topic.'\n",
    "\n",
    "        # Save chat\n",
    "        chat_history = history_manager.append_chat_pair(\n",
    "            chat_history, user_msg=user_input, assistant_msg=answer\n",
    "        )\n",
    "\n",
    "        return answer\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in RAG chain: {e}\")\n",
    "        fallback_responses = [\n",
    "            \"I'm having trouble accessing that information. Could you rephrase your question?\",\n",
    "            \"My knowledge base seems to be unavailable at the moment. Please try again later.\",\n",
    "            \"I encountered an unexpected error while processing your request.\"\n",
    "        ]\n",
    "        return random.choice(fallback_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f337b7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Item': {'messages': [{'user': {'content': 'what do you know about the CEO of AyataCommerce?', 'timestamp': '2025-06-02T16:45:08.926719'}, 'assistant': {'content': 'The CEO of AyataCommerce is Shine Mathew, who is the Founder of the company. He welcomes everyone to AyataCommerce and shares what it means to work at the company.', 'timestamp': '2025-06-02T16:45:08.926719'}}, {'user': {'content': 'Tell me about this company', 'timestamp': '2025-06-02T16:45:32.139576'}, 'assistant': {'content': 'AyataCommerce is a company that focuses on providing structure for its clients and a framework to understand the core issues they are solving. The CEO and Founder of AyataCommerce is Shine Mathew, who welcomes everyone to the company and emphasizes the values of empathy, inclusion, diversity, and respect. Employees describe AyataCommerce as a place where open communication, inclusion, and work-life balance are valued. The company encourages collaboration, professional growth, and flexible working arrangements. Microsoft Teams is the primary communication channel used within the organization.', 'timestamp': '2025-06-02T16:45:32.139576'}}, {'user': {'content': 'what do you know about him', 'timestamp': '2025-06-02T16:46:52.059322'}, 'assistant': {'content': 'Shine Mathew is the CEO and Founder of AyataCommerce. He welcomes everyone to AyataCommerce and emphasizes the meaning of working at Ayata.', 'timestamp': '2025-06-02T16:46:52.059322'}}, {'user': {'content': 'what do you know about the CEO of AyataCommerce?', 'timestamp': '2025-06-02T16:51:43.346899'}, 'assistant': {'content': 'Shine Mathew is the CEO and Founder of AyataCommerce. He has welcomed everyone to AyataCommerce and shared what it means to work at the company.', 'timestamp': '2025-06-02T16:51:43.346899'}}], 'user_id': '123', 'session_id': '1234'}, 'ResponseMetadata': {'RequestId': '9NUVBJHNMGR3II1D6K0P5R29P7VV4KQNSO5AEMVJF66Q9ASUAAJG', 'HTTPStatusCode': 200, 'HTTPHeaders': {'server': 'Server', 'date': 'Mon, 02 Jun 2025 11:26:43 GMT', 'content-type': 'application/x-amz-json-1.0', 'content-length': '1969', 'connection': 'keep-alive', 'x-amzn-requestid': '9NUVBJHNMGR3II1D6K0P5R29P7VV4KQNSO5AEMVJF66Q9ASUAAJG', 'x-amz-crc32': '218351597'}, 'RetryAttempts': 0}}\n",
      "Standalone question: What information is available about Shine Mathew, the CEO and Founder of AyataCommerce?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The context provides a welcoming message from Shine Mathew, the CEO and Founder of AyataCommerce, but does not offer detailed information about his background, achievements, or specific contributions to the company. For more detailed information, please contact HR at Ayatacommerce: hr@ayatacommerce.com.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"what do you know about the CEO of AyataCommerce?\",\"123\",\"1234\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3647385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standalone question: Could you provide information about the company AyataCommerce, including details about its CEO, Shine Mathew, and what it is like to work there?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AyataCommerce is a company that focuses on providing structure for its clients and a framework to understand the core issues they are solving. The CEO and Founder of AyataCommerce is Shine Mathew, who welcomes everyone to the company and emphasizes the values of empathy, inclusion, diversity, and respect. Employees describe AyataCommerce as a place where open communication, inclusion, and work-life balance are valued. The company encourages collaboration, professional growth, and flexible working arrangements. Microsoft Teams is the primary communication channel used within the organization.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"Tell me about this company\",\"123\",\"1234\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "336e6ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading from DynamoDB: An error occurred (ValidationException) when calling the Query operation: Query key condition not supported\n",
      "Standalone question: What information is available about the CEO of AyataCommerce?\n",
      "The CEO of AyataCommerce is Shine Mathew. He is the founder of the company and has welcomed everyone to AyataCommerce, highlighting what it means to work there.\n"
     ]
    }
   ],
   "source": [
    "print(chat(\"what do you know about the CEO of AyataCommerce?\", \"123\", \"1234\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "688fdf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading from DynamoDB: An error occurred (ValidationException) when calling the Query operation: Query key condition not supported\n",
      "Standalone question: Who is the person you are inquiring about, and what specific information are you interested in knowing about them?\n",
      "I don't have this information in my knowledge base. Please contact hr@ayatacommerce.com for assistance.\n"
     ]
    }
   ],
   "source": [
    "print(chat(\"what do you know about him\", \"123\", \"1234\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4c46978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standalone question: What is the current net worth of the specified company?\n",
      "I don't have this information in my knowledge base. Please contact hr@ayatacommerce.com for assistance.\n"
     ]
    }
   ],
   "source": [
    "print(chat(\"What is the net worth of this company?\", \"1234\", \"1234\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58cb922d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standalone question: What do you know about Shine Mathew, the CEO of AyataCommerce?\n",
      "Shine Mathew is the CEO and Founder of AyataCommerce. He welcomes everyone to AyataCommerce and emphasizes the meaning of working at Ayata.\n"
     ]
    }
   ],
   "source": [
    "print(chat(\"what do you know about him\", \"123\", \"1234\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
